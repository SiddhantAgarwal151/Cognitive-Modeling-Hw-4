{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5d2fae1",
   "metadata": {},
   "source": [
    "# Problem 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70229ded",
   "metadata": {},
   "source": [
    "### Lorenzo\n",
    "My main takeaway from this course was that a useful model is not a perfect model. I had previously held the belief that the best model would be one that could perfectly recreate real life. I thought that, as computing power became great enough, we could model occurances in their entirety as many times over as we like to create perfect models. But, as I learned in this course, that would entirely defeat the purpose of the model and make it no more usable than simply measuring things in real life. Like a map which covers the whole nation it is more useful to have a less faithful yet more manageable model.  \n",
    "A secondary consequence of this takeaway is that I am very glad so much is normally distributed, and that people smarter than I have already made the tools necessary for that modeling among many others. Absolute praise for the people who work on tools like stan, tensorflow, keras, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72f7b95",
   "metadata": {},
   "source": [
    "### Siddhant\n",
    "What struck me most about cognitive modeling was its interdisciplinary nature. Coming from a computer science background, I initially approached models as optimization problems—get the lowest error rate possible. But this course showed me that cognitive modeling sits at this fascinating intersection of psychology, neuroscience, and computation.\n",
    "I found myself particularly drawn to the Bayesian perspective. The idea that our brains might be performing something akin to probabilistic inference—constantly updating beliefs based on new evidence—resonated with me. It provides such an elegant framework for understanding how humans make decisions under uncertainty.\n",
    "The practical side was eye-opening too. Debugging computational models of cognition requires a completely different mindset than debugging regular code. When your model doesn't match human data, it's not necessarily a bug—it might be telling you something important about your theoretical assumptions.\n",
    "I also gained a new appreciation for the constraints we work within. The limitations aren't just computational—they're conceptual. How do you quantify concepts like attention or memory in a way that's both mathematically precise and psychologically meaningful? These questions make cognitive modeling intellectually challenging in ways I hadn't anticipated."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cognitive",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
